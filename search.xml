<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>hexo建站教程</title>
    <url>/p/3417200a.html</url>
    <content><![CDATA[<p>一直想搭一个博客，奈何一直比较懒。这次历尽千辛万苦，终于将网站搭起来了，把心血历程记录在这儿。使用的方式是hexo+next+github。</p>
<p><strong>hexo</strong>：一个基于nodeJS实现的博客框架。它的最大的作用就是能将 markdown文档自动转化成 html文档。markdown文档在格式上是比较友好的。</p>
<p><strong>next</strong>：hexo里面一个非常流行的主题，比较美观。 </p>
<p><strong>github</strong>：github page是一个静态网页平台。</p>
<p>主要流程就是，hexo把markdown文件转化为html文档，然后上传到GitHub，形成GitHub page。</p>
<h2><span id="安装hexo">安装hexo</span></h2><p>首先安装<a href="https://nodejs.org/en/">nodejs</a>，安装完成后输入<code>npm -v</code>，如果出现版本号，那说明安装成功了 </p>
<p>命令行安装hexo，如果是Windows的话，建议使用<code>git bash</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>

<p> 接下来就可以用hexo来生成博客了，先创建一个文件夹，如<code>myblog</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd myblog</span><br><span class="line">hexo init</span><br><span class="line">hexo generate</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure>

<p>执行完以后会提示访问 <code>localhost:4000</code>，就可以看到首页了。之后调试的时候会经常用到下面命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo generate &amp;&amp; hexo server </span><br></pre></td></tr></table></figure>

<h2><span id="安装next主题">安装next主题</span></h2><p><code>next</code>主题是一个比较美观流行的hexo主题，需要在博客根目录下，即<code>myblog</code>目录，执行以下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;iissnan&#x2F;hexo-theme-next themes&#x2F;next</span><br></pre></td></tr></table></figure>

<p>需要注意的是，next主题新版本和老版本仓库不一样，很多人建议使用新版本，因为新版本集成了很多新功能。不过我觉得老版本的风格比较喜欢，这个看个人喜好了。</p>
<p>老版本：<a href="https://github.com/iissnan/hexo-theme-next">iissnan</a> 最新版本是<code>5.1.4</code>，已经不维护了。</p>
<p>新版本：<a href="https://github.com/theme-next/hexo-theme-next">theme-next</a>持续更新中。</p>
<h2><span id="hexo-next配置">hexo next配置</span></h2><p>主题配置主要参考：<a href="https://www.jianshu.com/p/9f0e90cc32c2">hexo next 主题优化</a></p>
<h2><span id="关联githubio">关联github.io</span></h2><p>建一个同名的仓库，然后在<code>hexo</code>配置文件里面进行设置，比如你的用户名叫<code>zhangsan</code>，那仓库名就叫<code>zhangsan.github.io</code>，hexo关联<code>github.io</code>的方法参考网上教程，这里说下重要的步骤：</p>
<p>在博客目录配置文件<code>_config.yml</code>最后面添加deploy字段如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deploy:  </span><br><span class="line">  type: git  </span><br><span class="line">  repo: git@github.com:UserName&#x2F;Blog.git  </span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>

<p>安装<code>hexo-deployer-git</code>，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>

<p>部署命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo generate &amp;&amp; hexo deploy </span><br></pre></td></tr></table></figure>

<p>这样就可以推送到远程仓库，等待一会儿访问<code>zhangsan.github.io</code> 就可以访问到了</p>
<h2><span id="关联域名">关联域名</span></h2><p>把<code>zhangsan.github.io</code>与域名关联起来，阿里云的域名一年只要一块钱，简直白嫖</p>
<h2><span id="hexo基本使用">hexo基本使用</span></h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g 或 hexo generate   # 在hexo站点根目录下生成public文件夹</span><br><span class="line">hexo c 或 hexo clean      # 把public文件夹删除</span><br><span class="line">hexo s 或 hexo server     # 在本地启动服务，默认地址为 http:&#x2F;&#x2F;localhost:4000&#x2F;</span><br><span class="line">hexo d 或 hexo deploy     # 部署站点，在本地生成.deploy_git文件夹，并将编译后的文件上传至 GitHub</span><br><span class="line"></span><br><span class="line">hexo new [layout] &lt;title&gt; # 例如hexo new photo “my-first-blog” 会尝试在scaffolds中寻找 </span><br><span class="line">                            photo.md布局，若找到，则根据该布局新建文章；若未找到或指令中未指定该参数</span><br><span class="line">                            ，则使用post.md新建文章。</span><br><span class="line">hexo clean &amp;&amp; hexo g      # 删除，讲source&#x2F;_posts文件夹下的文章源文件删除后，执行该命令</span><br></pre></td></tr></table></figure>



<h2><span id="遇到的一些问题">遇到的一些问题</span></h2><p><a href="https://blog.csdn.net/qq_44852901/article/details/122817214">Archieve 无法打开解决办法</a></p>
<p><a href="https://www.zhihu.com/question/353097489">Cannot GET /about/%20 解决办法</a></p>
<p><a href="https://www.cnblogs.com/Createsequence/p/14150758.html">目录无法跳转</a></p>
]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>建站</tag>
      </tags>
  </entry>
  <entry>
    <title>埋点数据上报架构比较</title>
    <url>/p/417edfd3.html</url>
    <content><![CDATA[<h2><span id="前言">前言</span></h2><p>埋点数据是大部分互联网公司数据组的重要数据来源，另一个重要来源是业务数据。一般埋点数据体量要比业务数据大很多。正式因为海量的埋点数据，对用户行为的分析，精准推荐才成为了可能， 本文对目前所见的埋点数据上报架构进行了梳理，并分析其优缺点。</p>
<h2><span id="数据上报架构">数据上报架构</span></h2><h3><span id="第一种">第一种</span></h3><p>这种方式全部埋点数据都打往一个topic，所有的埋点共用一套schema，这个schema中包括了公共字段，以及自定义字段，公共字段又可以分为必选字段和可选字段，某些必选字段是打点的sdk自动获取值，不需要用户去指定值；自定义字段塞在一个map中，并且规定，该map中只能存储&lt;string, string&gt;类型，上报的架构大概如下：</p>
<p><img src="/p/417edfd3/1.jpg"></p>
<p>上报时候所有的数据都会上报到同一个kafka topic中，这个kafka分区会很多，用flink消费该topic落盘到hive，这个flink任务会有很大的并行度，这样一来只用维护一个flink任务就可以，如果新增打点，不用修改该flink任务，当打点数量太多的时候，需要对该kafka topic进行扩容，增加flink任务并行度，扩容时会影响所有的事件上报，罗盘到hive因为是flink任务，所以是实时写入，但是只有该小时全部落盘后才会提交分区，因此相当于小时级别延迟</p>
<p>在实践中，对于推荐，或者一些实时算数场景而言，需要实时拿到所需要的数据，此时这种小时级别肯定不适用，解决方法时从总的kafka根据某些规则向其他topic进行分流（上图中右下部分）分流的topic 可以被flink消费或者订阅到带预聚合的olap引擎中去，或者送入实时模型，提高时效性</p>
<h3><span id="第二种">第二种</span></h3><p>这种方式每个埋点事件都会发送到对应的kafka topic中去，其后会跟一个flink任务订阅该topic，落盘到hdfs，每个事件的schema由用户自己定义，flink任务需要指定相应的schema去解析数据，大致的架构如下：</p>
<p><img src="/p/417edfd3/2.jpg"></p>
<p>每个事件只会上报到一个对应的topic，每个flink程序只消费一个topic，落到hdfs，作为离线原始数据。如果用户需要再去实时处理的话，可以订阅这个kafka，落盘到druid或者ck这种时效性高的计算引擎。这样不必再去维护一套分流程序，不过每次新添加事件之后，需要创建一个topic，同时增加一个flink任务，flink任务维护成本比较高，如果某个事件流量上涨，只用单独修改该事件对应的topic和flink任务即可，不影响其他事件。</p>
<h2><span id="总结">总结</span></h2><table>
<thead>
<tr>
<th>维度</th>
<th>第一种</th>
<th>第二种</th>
</tr>
</thead>
<tbody><tr>
<td>schema</td>
<td>统一的schema</td>
<td>不统一schema</td>
</tr>
<tr>
<td>topic</td>
<td>上报到一个topic</td>
<td>每个单独的topic</td>
</tr>
<tr>
<td>flink</td>
<td>一个flink任务</td>
<td>每个单独的flink任务</td>
</tr>
<tr>
<td>hive</td>
<td>一个hive表</td>
<td>每个事件一张表</td>
</tr>
<tr>
<td>实时消费</td>
<td>需要额外的分流程序</td>
<td>不需要额外的分流</td>
</tr>
<tr>
<td>扩容</td>
<td>会影响所有事件</td>
<td>只会影响单个事件</td>
</tr>
</tbody></table>
<p>一般而言，第一种比较适合于数据量小的场景，第二种适合大数据量场景</p>
<p><strong>tips</strong>:一般上报字段建议命名使用下划线命名，避免驼峰命名，由于hive对大小写不敏感，驼峰命名很多时候容易出问题</p>
]]></content>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
</search>
